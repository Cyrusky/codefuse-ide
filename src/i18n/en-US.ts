export const localizationBundle = {
  languageId: 'en-US',
  languageName: 'English',
  localizedLanguageName: 'English',
  contents: {
    'common.about': 'About',
    'common.preferences': 'Preferences',
    'common.newWindow': 'New Window',
    'common.newWindowDesc': 'Open a new window',

    'custom.quick_open': 'Quick Open',
    'custom.command_palette': 'Command Palette',
    'custom.terminal_panel': 'Switch to Terminal Panel',
    'custom.search_panel': 'Switch to Search Panel',

    'preference.ai.native.local_model.title': 'Local Model',
    'preference.ai.native.local_model.complete_url': 'Model URL',
    'preference.ai.native.local_model.api_key': 'API Key',
    'preference.ai.native.local_model.chat': 'Chat',
    'preference.ai.native.local_model.chat.model_name': 'Chat Model Name',
    'preference.ai.native.local_model.chat.system_prompt': 'Chat - System Prompt',
    'preference.ai.native.local_model.chat.temperature': 'Chat - temperature',
    'preference.ai.native.local_model.chat.max_tokens': 'Chat - max_tokens',
    'preference.ai.native.local_model.chat.presence_penalty': 'Chat - presence_penalty',
    'preference.ai.native.local_model.chat.top_p': 'Chat - top_p',
    'preference.ai.native.local_model.code_completion': 'Code completion',
    'preference.ai.native.local_model.code_completion.model_name': 'Code Completion Model Name',
    'preference.ai.native.local_model.code_completion.model_name.tooltip': 'The default is same as Chat Model Name',
    'preference.ai.native.local_model.code_completion.system_prompt': 'Code Completion - System Prompt',
    'preference.ai.native.local_model.code_completion.user_prompt': 'Code Completion - User Prompt',
    'preference.ai.native.local_model.code_completion.user_prompt.tooltip': '{prefix} will be replaced with the precursor code, {suffix} will be replaced with the post-cursor code',
    'preference.ai.native.local_model.code_completion.temperature': 'Code Completion - temperature',
    'preference.ai.native.local_model.code_completion.max_tokens': 'Code Completion - max_tokens',
    'preference.ai.native.local_model.code_completion.presence_penalty': 'Code Completion - presence_penalty',
    'preference.ai.native.local_model.code_completion.top_p': 'Code Completion - top_p',
    'preference.ai.native.local_model.temperature.description': 'What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\nWe generally recommend altering this or top_p but not both.',
    'preference.ai.native.local_model.max_tokens.description': 'The maximum number of tokens that can be generated in the chat completion.',
    'preference.ai.native.local_model.presence_penalty.description': 'Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model\'s likelihood to talk about new topics.',
    'preference.ai.native.local_model.top_p.description': 'An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.\nWe generally recommend altering this or temperature but not both.',

    'ai.local_model.noConfig': 'Please configure the AI model service for a better experience',
    'ai.local_model.go': 'Go',

    'autoUpdater.checkForUpdates': 'Check for Updates...'
  },
};
